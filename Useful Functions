#check the dataset and structure
summary(dataset)
str(dataset)


#Linear Regression
lm(  x ~ y, data = dataset)

#Logistic Regression
glm(x ~ y+z+a+b..., family = binomial,data = dataset)
coef
AIC
library(MASS)
StepAIC(model, trace = 0)
R2
Model Fitting :
PseudoR2
------------------------------------------------
McFadden
Cox n Snell
Nagelkerke
Reasonable if > 0.2
Good if > 0.4
Very good if > 0.5
-------------------------------------------------------------
library(descr)
LogRegR2(datamodel)
library(SDMTools)
predict(datamodel, type = "response",na.action = na.exclude)
confusion matrix
confusion.matrix(dataset$variable, dataset$predictedvariable, threshold = 0.5)
accuracyfull <- sum(diag(confMatrixModelFull)) / sum(confMatrixModelFull)
Payback matrix
Cross validation:
---------------------------------
library(boot)
# Accuracy function
costAcc <- function(r, pi = 0) {
  cm <- confusion.matrix(r, pi, threshold = 0.3)
  acc <- sum(diag(cm)) / sum(cm)
  return(acc)
}

# Cross validated accuracy for model
set.seed(534381)
cv.glm(dataset, model, cost = costAcc, K = 6)$delta[1]

--------------------------------------------------------------------------
# Split data in train and test set
set.seed(534381) 
dataset$isTrain <- rbinom(nrow(dataset), 1, 0.66)
train <- subset(dataset, dataset$isTrain == 1)
test <- subset(dataset, dataset$isTrain == 0)

logitTrainNew <- glm(formulaLogit, family = binomial, data = train) # Modeling  
test$predNew <- predict(logitTrainNew, type = "response", newdata = test) # Predictions

# Out-of-sample confusion matrix and accuracy
confMatrixModelNew <- confusion.matrix(test$originalvariable, test$predNew, threshold = 0.3) 
sum(diag(confMatrixModelNew)) / sum(confMatrixModelNew) # Compare this value to the in-sample accuracy


